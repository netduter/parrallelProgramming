Παράλληλοι Υπολογιστές και Αλγόριθμοι
=====================================

Σειριακό Πρόγραμμα
------------------

Το σειριακό πρόγραμμα βρίσκεται στο αρχείο ``src/main.c``.

Απλά διαβάζει το αρχείο και υπολογίζει ακολουθιακά το GC content.

Παίρνει ως παραμέτρους το όνομα του FASTQ αρχείου που διαβάζει
και το όνομα ενός αρχείου στο οποίο γράφει τα αποτελέσματα.

.. sourcecode:: sh

   $ make main # compile program
   $ build/main 'data/100.fastq' 'out/main-100.tsv'


Παράλληλο Πρόγραμμα MPI
-----------------------

Το παράλληλο πρόγραμμα έχει υλοποιηθεί με χρήση MPI στο αρχείο ``src/mpi.c``.

Η υλοποίηση περιλαμβάνει τα εξής βήματα:

* Προεπεξεργασία του αρχείου για τον υπολογισμό των ακολουθιών.
* Δημιουργία ενός μεγάλου μηνύματος που περιέχει όλες τις ακολουθίες.
* Αποστολή του με ``MPI_Bcast`` σε όλους τους workers.
* Λήψη των αποτελεσμάτων με ``MPI_Recv``.
* Αποθήκευση των αποτελεσμάτων σε αρχείο.

Η παραπάνω υλοποίηση είναι η ταχύτερη που καταφέραμε στο MPI και
χρησιμοποιεί τον ελάχιστο αριθμό αποστολής και λήψης μηνυμάτων.

Παίρνει ως παραμέτρους το όνομα του FASTQ αρχείου που διαβάζει
και το όνομα ενός αρχείου στο οποίο γράφει τα αποτελέσματα.

.. sourcecode:: sh

   $ make mpi # compile program
   $ mpirun -np 10 -hostfile ~/hostfiles build/mpi 'data/100.fastq' 'out/mpi-100.tsv'


Παράλληλο Πρόγραμμα OpenMP
--------------------------

Το παράλληλο πρόγραμμα έχει υλοποιηθεί επίσης με χρήση OpenMP στο αρχείο ``src/omp.c``.

Η υλοποίηση περιλαμβάνει τα εξής βήματα:

* Προεπεξεργασία του αρχείου για τον υπολογισμό των ακολουθιών.
* Στο κομμάτι που εκτελείται παράλληλα κάθε thread ανοίγει ένα
  file descriptor με το αρχείο και διαβάζει το τμήμα που του
  αντιστοιχεί. (Υπολογίζεται με βάση τον αριθμό του thread).
* | Τα αποτελέσματα της επεξεργασίας αποθηκεύονται σε ξεχωριστά προσωρινά αρχεία.
  | Η ονοματοδοσία τους είναι τέτοια ώστε να αναγνωρίζεται εύκολα το thread.
* Μόλις τελειώσει το παράλληλο τμήμα του προγράμματος τα
  προσωρινά αρχεία συνενώνονται σε ένα τελικό και διαγράφονται.

Παίρνει ως παραμέτρους το όνομα του FASTQ αρχείου που διαβάζει,
το όνομα ενός αρχείου στο οποίο γράφει τα αποτελέσματα,
και τον αριθμό των threads στα οποία θα τρέξει.

.. sourcecode:: sh

   $ make omp # compile program
   $ build/omp 'data/100.fastq' 'out/omp-100.tsv' 10


Ο αριθμός των threads μπορεί επίσης να οριστεί ενώ γίνεται compile.

.. sourcecode:: sh

   $ make NPROCS=10 omp # compile & set threads to 10
   $ build/omp 'data/100.fastq' 'out/omp-100.tsv'

Αποτελέσματα
------------

Διαγράμματα
^^^^^^^^^^^

Στατιστικά στοιχεία για τους χρόνους εκτέλεσης (σε milliseconds) της
κάθε υλοποίησης έπειτα από 10 εκτελέσεις φαίνονται στους παρακάτω πίνακες.

.. plot:: tables.py

.. raw:: latex

    \clearpage

Επίσης, στο ακόλουθο διάγραμμα φαίνονται οι ρυθμοί αύξησης
των χρόνων εκτέλεσης όσο αυξάνεται ο αριθμός των ακολουθιών.

Παρατηρούμε πως δεν υπάρχει αξιοσημείωτη διαφορά μεταξύ
του χρόνου του σειριακού προγράμματος και του OpenMP.

*Δεν συμπεριλάβαμε το MPI λόγω της τεράστιας χρονικής
διαφοράς που έχει σε σχέση με τις άλλες υλοποιήσεις.*

.. plot:: lines.py

.. raw:: latex

    \clearpage

Επιταχύνσεις
^^^^^^^^^^^^

Γνωρίζουμε ότι ο τύπος της επιτάχυνσης είναι :math:`S = \frac{T_{s}}{T_{p}}`
όπου :math:`T_{s}` είναι ο χρόνος εκτέλεσης του σειριακού προγράμματος
και :math:`T_{p}` ο χρόνος εκτέλεσης του παράλληλου.

OpenMP
~~~~~~

* 100 ακολουθίες: :math:`S = \frac{12.119}{16.518} \approx 0.734`
* 10K ακολουθίες: :math:`S = \frac{89.807}{80.439} \approx 1.116`
* 100K ακολουθίες: :math:`S = \frac{547.623}{537.708} \approx 1.018`

MPI
~~~

* 100 ακολουθίες: :math:`S = \frac{12.119}{2517.573} \approx 0.005`
* 10K ακολουθίες: :math:`S = \frac{89.807}{3269.196} \approx 0.027`
* 100K ακολουθίες: :math:`S = \frac{547.623}{5678.939} \approx 0.096`


----

Ο κώδικας μαζί με επιπλέον σχόλια για τα πειράματα που κάναμε υπάρχει στο GitHub_.

.. _GitHub: https://github.com/netduter/parrallelProgramming
